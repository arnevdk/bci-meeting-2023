\documentclass[25pt, a0paper, landscape]{tikzposter}

% Preamble
\usepackage{tikz}
\usetikzlibrary{positioning}
\usetikzlibrary{arrows.meta,arrows}
\usepackage{tcolorbox}
\usepackage{xcolor}
\usepackage[backend=biber]{biblatex}
\usepackage{colortbl}
\usepackage[default,oldstyle,scale=0.95]{opensans} %% Alternatively
%% use the option 'defaultsans' instead of 'default' to replace the
%% sans serif font only.
\usepackage[T1]{fontenc}
\usepackage{tikz,pgfplots,pgfplotstable}
\pgfplotsset{compat=1.8}

% Layout

\definecolor{GeoDataViz_blue}{HTML}{009ADE}
\definecolor{GeoDataViz_magenta}{HTML}{FF1F5B}
\definecolor{GeoDataViz_green}{HTML}{00cd6c}

\definecolor{GeoDataViz_purple}{HTML}{AF58BA}
\definecolor{GeoDataViz_yellow}{HTML}{FFC61E}
\definecolor{GeoDataViz_orange}{HTML}{F28522}

\definecolor{GeoDataViz_amber}{HTML}{FFAA00}
\definecolor{GeoDataViz_red}{HTML}{E9002D}

\definecolor{BlockColor}{HTML}{9c64e0}


%% Title
\colorlet{backgroundcolor}{white}
\definetitlestyle{mytitle}{
	width=.99\linewidth,
}{}
\usetitlestyle{mytitle}
%%% Title wrap
\makeatletter
\def\title#1{\gdef\@title{\scalebox{\TP@titletextscale}{%
			\begin{minipage}[t]{\linewidth}
				#1
				\par
			\end{minipage}%
		}}}
\makeatother
%%% Title structure
\makeatletter
\renewcommand\TP@maketitle{%
	\begin{minipage}[t]{0.35\linewidth}
		\color{titlefgcolor}
		{\fontseries{sb}\selectfont \Huge {\@title}}
		{\large \@author \par}
		{\@institute \par}
	\end{minipage}%
	\hfill
	\begin{minipage}[t]{0.65\linewidth}
		~\\
		\hspace*{\fill}\@titlegraphic
	\end{minipage}
}
\makeatother

%% Block
\defineblockstyle{myblock}{
	titleleft, roundedcorners=0, linewidth=10pt,
}{
	\draw[color=framecolor, fill=blockbodybgcolor,
		rounded corners=\blockroundedcorners] (blockbody.south west)
	rectangle (blockbody.north east);
	\ifBlockHasTitle
		\draw[color=framecolor, fill=blocktitlebgcolor,
			rounded corners=\blockroundedcorners] (blocktitle.south west)
		rectangle (blocktitle.north east);
	\fi
}
\useblockstyle{myblock}

% Metadata
\title{Classifier-based latency estimation for covert attention ERP decoding}
\author{
	Arne Van Den Kerchove\textsuperscript{*,1,2},
	Hakim Si-Mohammed\textsuperscript{1},
	Marc Van Hulle\textsuperscript{2},
	Fran√ßois Cabestaing\textsuperscript{1}
}
\date{\today}
\institute{
	\textsuperscript{1}UMR CRIStAL, Univ. de Lille, Lille, France \\
	\textsuperscript{2}Lab for Neuro- and Psychophysiology, KU Leuven, Leuven, Belgium}
\titlegraphic{
	\includegraphics[height=8em]{figures/ulille.png}\hspace{1em}
	\includegraphics[height=8em]{figures/cristal.png}\hspace{1em}
	\includegraphics[height=8em]{figures/kul.png}
}
\addbibresource{references.bib}

\begin{document}
\maketitle
\begin{columns}
	\column{0.33}
	\colorlet{blockbodybgcolor}{black!10}
	\colorlet{blockbodyfgcolor}{black!80}
	\colorlet{blocktitlebgcolor}{BlockColor}
	\colorlet{blocktitlefgcolor}{white}
	\colorlet{framecolor}{black!50}
	\block{1. Gaze-independent visual oddball interface}{
		\subsection*{\color{black} Eye motor disability}

		\begin{minipage}{.48\linewidth}
			The BCI target population suffers from \textcolor{black}{eye motor disabilities}. This warrants the development of gaze-independent communication paradigms. While other active BCI modalities (auditory, somatosensory, ...) can work, visual paradigms exploiting \textcolor{black}{spatial attention} often yield the highest ITR~\cite{Riccio2012}.
		\end{minipage}%
		\hfill
		\begin{minipage}{.48\linewidth}
			\centering

			\textcolor{black}{Eye motor disabilities in patients}
			\bigskip


			\begin{tikzpicture}
				\begin{axis}[
						xbar stacked,
						symbolic y coords ={ALS,MS,Stroke,LiS},
						xlabel={incidence},
						bar width=.7em,
						legend style={
								at={(0.5,-0.30)},
								anchor=north,
								legend columns=-1,
								draw=none,
								fill=none,
							},
						axis line style={draw=none},
						tick style={draw=none},
						xtick=\empty
					]
					\addplot+[fill=BlockColor!33, draw=none] coordinates{
							(50,ALS)
							(31,MS)
							(55,Stroke)
							(0,LiS)
						};
					\addplot+[fill=BlockColor!66, draw=none] coordinates{
							(33,ALS)
							(31,MS)
							(0,Stroke)
							(98,LiS)
						};
					\addplot+[fill=BlockColor, draw=none] coordinates{
							(17,ALS)
							(0,MS)
							(0,Stroke)
							(2,LiS)
						};

					\legend{\strut minor, \strut severe, \strut complete}
					\draw[color=gray] (axis cs:0,LiS) to (axis cs:100,LiS);
					\draw[color=gray] (axis cs:0,Stroke) to (axis cs:100,Stroke);
					\draw[color=gray] (axis cs:0,MS) to (axis cs:100,MS);
					\draw[color=gray] (axis cs:0,ALS) to (axis cs:100,ALS);

				\end{axis}




			\end{tikzpicture}

			%\begin{tabular}{@{}|l|rrr|r|@{}}
			%	\hline
			%	         & ALS  & MS   & Stroke  &
			%	\cellcolor{BlockColor}\textbf{LiS}                                         \\ \hline
			%	Minor    & 50\% & 31\% & 40-70\% & \cellcolor{BlockColor}                  \\
			%	Severe   & 33\% & 3\%  & +       & \cellcolor{BlockColor}\color{black}98\% \\
			%	Complete & 17\% & -    & +       & \cellcolor{BlockColor}\color{black}2\%  \\ \hline
			%\end{tabular}
		\end{minipage}


		\subsection*{Visual attention settings}
		%\includegraphics[width=\linewidth]{figures/attention_modes.eps}
		%Usually, a visual brain-computer interface is operated in \textbf{overt} attention mode, where the user directs their gaze to the intended target.
		%Patients with eye motor disabilities are not always able to comfortably perform overt attention.
		%Hence, \textbf{covert} attention paradigms have been designed where the user gazes at the center of the screen and selects targets in their visual periphery. Covert attention suffers from poor decoding performance, but this can be improved using \textbf{jitter correction}~\cite{Arico2014}. Further dissociating mental and visual attention

		%		\note{overt attention}

		\begin{tcolorbox}[sharp corners=all,
				colback=GeoDataViz_blue,coltext=white,
				fontupper=\bfseries,boxrule=0mm,boxsep=5mm,
			]
			Overt attention
		\end{tcolorbox}

		\begin{minipage}{.48\linewidth}
			\includegraphics[width=\linewidth]{figures/attention_overt.pdf}
		\end{minipage}%
		\hfill%
		\begin{minipage}{.48\linewidth}
			Persons with full eye motor control can gaze at intended targets.
		\end{minipage}%
		\bigskip
		\bigskip

		\begin{tcolorbox}[sharp corners=all,
				colback=GeoDataViz_magenta,coltext=white,
				fontupper=\bfseries,boxrule=0mm,boxsep=5mm,
			]
			Covert attention
		\end{tcolorbox}


		\begin{minipage}{.48\linewidth}
			\includegraphics[width=\linewidth]{figures/attention_covert.pdf}
		\end{minipage}%
		\hfill%
		\begin{minipage}{.48\linewidth}
			Fixating the gaze at the center is a common solution, but this also requires a degree of eye motor control.
		\end{minipage}%
		\bigskip
		\bigskip

		\begin{tcolorbox}[sharp corners=all,
				colback=GeoDataViz_green,coltext=white,
				fontupper=\bfseries,boxrule=0mm,boxsep=5mm,
			]
			Split attention
		\end{tcolorbox}


		\begin{minipage}{.48\linewidth}
			\includegraphics[width=\linewidth]{figures/attention_split.pdf}
		\end{minipage}%
		\hfill%
		\begin{minipage}{.48\linewidth}
			We design an interface that allows for the split attention conditions that can occurr in patients with involuntary eye movements.
		\end{minipage}%




		\subsection*{Experimental protocol}
		\includegraphics[width=\linewidth]{figures/paradigm.eps}
	}


	\column{0.33}
	\block{2. Novel ERP latency estimation procedure}{
		\subsection*{The jitter problem}
		Covert attention decoding suffers from the jitter problem ILLUSTRATE~
		Covert attention decoding can be improved by jitter correction~\cite{Arico2014}
		Classifier-based latency estimation~\cite{Mowla2017}, paired with a time-regularized linear classifier~\cite{Sosulski2022},
		can yield the latencies to correct ERP jitter.


		\subsection*{Woody Classifier-Based Latency Estimation (wCBLE)}
		\begin{tikzfigure}
			\begin{tikzpicture}
				\node[draw,align=center](class){Spatiotemporal \\ classifier weights};
				\node[below=of class,align=center](xcorr) {$\star$};
				\node[below=.5of xcorr](a1){};
				\node[draw,below=.5 of a1,align=center, xshift=-1.5in](latency) {Latencies};
				\node[draw,below=.5 of a1,align=center,xshift=1.5in](wav) {Wavelet coefs};
				\node[draw,left=of class,align=center](epochs) {Epochs};
				\node[left=3 of latency, align=center, text=BlockColor](align){align to \\ latencies};
				\node[below=.5of latency, xshift=1.5in](a2){};
				\node[draw, below= of a2,align=center](svm) {SVM};
				\node[left=.5of epochs](a3){};


				\draw[-{Latex[length=.2in]}] (epochs) to (class);
				\draw[-{Latex[length=5mm]}] (epochs) |- (class);
				\draw (class) to (xcorr);
				\draw (xcorr) to (a1.center);
				\draw[-{Latex[length=5mm]}] (a1.center) -| (latency);
				\draw[-{Latex[length=5mm]}] (a1.center) -| (wav);
				\draw (epochs) |- (xcorr);
				\draw (latency) |- (a2.center);
				\draw (wav) |- (a2.center);
				\draw[-{Latex[length=5mm]}] (a2.center)  to (svm);
				\draw[color=BlockColor] (latency)  to (align);
				\draw[,color=BlockColor] (align.north)  |- (a3.center);
				\draw[-{Latex[length=5mm]},color=BlockColor] (a3.center)  to (epochs);

			\end{tikzpicture}


		\end{tikzfigure}

		\bigskip
		\textbf{Convergence}

		\includegraphics[width=\linewidth]{figures/convergence.png}

		\bigskip
		\textbf{Alignment}
	}

	\column{0.33}
	\block{3. Improvement in covert attention decoding}{
		\begin{enumerate}
			\item Band-pass .5 to 32Hz
			\item Resample to 64Hz
			\item ICA Eye artifact rejection
			\item Remove bad trials according to eye-tracker
			\item Subtract non-target average
		\end{enumerate}

		\includegraphics[width=.5\linewidth]{figures/classification_results_diff.png}

		\includegraphics[width=\linewidth]{figures/classification_results_rel.eps}
	}

	\block{Conclusion}{
		\begin{enumerate}
			\item
			\item
			\item Algorithm that can be used in online decoding
		\end{enumerate}
	}
	\colorlet{blockbodybgcolor}{gray!20}

	\block{References}{
		\printbibliography[heading=none]
	}
\end{columns}

\end{document}
